# LocalChat

Chat using pywhispercpp and ollama

I wrote this to run on MacOS.  I think it shouls run okay on linux and windows too, but I haven't tried it.  Let me know if you do.

pip install -r requirements.txt

python localchat.py


Take a look at this version by my friend.  It needs some work, but it demonstrates using the streaming capability of langchain's LLM module:  https://github.com/abdeladim-s/llm-chatter/blob/main/llm_chatter/main.py   

